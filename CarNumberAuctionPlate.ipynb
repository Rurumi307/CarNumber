{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe4980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "def generate_lucky_numbers():\n",
    "    \"\"\"\n",
    "    Generate lucky numbers based on specific criteria and target sums.\n",
    "    \n",
    "    This function generates lucky numbers by considering different combinations of four digits\n",
    "    and checking their sums against predefined target sums. It also assigns categories to\n",
    "    the lucky numbers based on certain conditions.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing generated lucky numbers and their categories.\n",
    "    \"\"\"\n",
    "    # Define the target sums and possible digits\n",
    "    target_sums = [8, 11, 13, 15, 16, 17, 18, 21, 23, 24, 25, 29, 31, 32, 33, 35, 37, 39]\n",
    "\n",
    "    # Define lucky number categories and their associated values\n",
    "    lucky_dict = {\n",
    "        '伏位': [11, 22, 33, 44, 66, 77, 88, 99],\n",
    "        '延年': [19, 91, 78, 87, 43, 34, 26, 62],\n",
    "        '生氣': [14, 41, 67, 76, 93, 39, 28, 82],\n",
    "        '天醫': [13, 31, 68, 86, 94, 49, 72, 27],\n",
    "    }\n",
    "\n",
    "    # Initialize a list to store lucky numbers\n",
    "    lucky_numbers = []\n",
    "\n",
    "    # Generate all possible combinations of four digits\n",
    "    combinations = itertools.product(range(10), repeat=4)\n",
    "\n",
    "    # Iterate through each combination\n",
    "    for combination in combinations:\n",
    "        if 4 not in combination:\n",
    "            total_sum = sum(combination)\n",
    "\n",
    "            # Check if the total sum matches a target sum\n",
    "            if total_sum in target_sums:\n",
    "                sorted_combination_int = ''.join(map(str, combination))\n",
    "\n",
    "                # Determine the lucky number category\n",
    "                category = \"普通\"\n",
    "                for key, values in lucky_dict.items():\n",
    "                    if int(sorted_combination_int) % 100 in values:\n",
    "                        category = key\n",
    "                        break\n",
    "                # Append the lucky number to the list\n",
    "                lucky_numbers.append({\"類別\": category, \"號碼\": sorted_combination_int, '總和': total_sum})\n",
    "    \n",
    "    # Create a DataFrame from the list of lucky numbers and drop duplicates\n",
    "    lucky_number_df = pd.DataFrame(lucky_numbers).drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    return lucky_number_df\n",
    "\n",
    "# Generate lucky numbers and save them to an Excel file\n",
    "lucky_numbers_df = generate_lucky_numbers()\n",
    "lucky_numbers_df.to_excel(\"./result/lucky_number.xlsx\", index=False)\n",
    "lucky_numbers_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7deb097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "section_list = [{\"20\":\"臺北市區\"}, {\"40\":\"臺北區\"}, {\"50\":\"新竹區\"}, {\"60\":\"臺中區\"}, {\"70\":\"嘉義區\"}, {\"30\":\"高雄市區\"}, {\"80\":\"高雄區\"}]\n",
    "station_text = \"\"\"[\"20-臺北市區監理所\",\"21-士林監理站\",\"25-基隆監理站\",\"26-金門監理站\",\"28-連江監理站\"];\n",
    "[\"40-臺北區監理所\",\"41-板橋監理站\",\"43-宜蘭監理站\",\"44-花蓮監理站\",\"45-玉里監理分站\",\"46-蘆洲監理站\"];\n",
    "[\"50-新竹區監理所\",\"51-新竹市監理站\",\"52-桃園監理站\",\"53-中壢監理站\",\"54-苗栗監理站\"];\n",
    "[\"60-臺中區監理所\",\"61-臺中市監理站\",\"62-南投監理站埔里分站\",\"63-豐原監理站\",\"64-彰化監理站\",\"65-南投監理站\"];\n",
    "[\"70-嘉義區監理所\",\"71-東勢監理分站\",\"72-雲林監理站\",\"73-新營監理站\",\"74-臺南監理站\",\"75-麻豆監理站\",\"76-嘉義市監理站\"];\n",
    "[\"30-高雄市區監理所\",\"31-苓雅監理站\",\"33-旗山監理站\"];\n",
    "[\"80-高雄區監理所\",\"81-臺東監理站\",\"82-屏東監理站\",\"83-恆春監理分站\",\"84-澎湖監理站\"]\"\"\"\n",
    "\n",
    "# Initialize a dictionary to store station information\n",
    "station_dict = {}\n",
    "\n",
    "# Regular expression pattern to match items inside []\n",
    "pattern = r'\\[([^]]+)\\]'\n",
    "\n",
    "# Loop through the split text and extract lists inside []\n",
    "for idx, item in enumerate(station_text.split(';')):\n",
    "    match = re.search(pattern, item)\n",
    "    if match:\n",
    "        extracted = eval(match.group(1))\n",
    "        for i in extracted:\n",
    "            station_code, station_name = i.split('-')\n",
    "            section_code = list(section_list[idx].keys())[0]\n",
    "            station_dict[station_name] = {\"stationCode\": station_code, \"sectionCode\": section_code}\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_number_of_pages(url, headers, **params):\n",
    "    \"\"\"\n",
    "    Extract the number of pages from the specified URL for a given set of parameters.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL pattern for querying auction data.\n",
    "        headers (dict): HTTP headers for the request.\n",
    "        **params: Additional parameters for the URL.\n",
    "\n",
    "    Returns:\n",
    "        int: The total number of pages with auction data.\n",
    "    \"\"\"\n",
    "    response = requests.get(url.format(page=1, **params), headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    text = soup.find(\"span\", id=\"pagebanner\").get_text()\n",
    "    numbers = [char for char in text.split('，')[0] if char.isdigit()]\n",
    "    number = int(''.join(numbers))\n",
    "\n",
    "    return number\n",
    "\n",
    "def scrape_page_data(url, headers, page, action, **params):\n",
    "    \"\"\"\n",
    "    Scrape data from a specific page of the Taiwan Motor Vehicle Driver Information Service (MVDis) website.\n",
    "    \n",
    "    This function sends a GET request to the provided URL with the specified page number and parameters.\n",
    "    It then extracts auction or bidding data from the page's HTML content based on the action.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL pattern for querying the MVDis website.\n",
    "        headers (dict): The headers for the HTTP request.\n",
    "        page (int): The page number to scrape.\n",
    "        action (str): The action to perform: 'bidding' or 'auction_records'.\n",
    "        **params: Additional parameters to include in the URL for customization.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing scraped data for each row on the page.\n",
    "    \"\"\"\n",
    "    print(page)\n",
    "    response = requests.get(url.format(page=page, **params), headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    rows = soup.find_all('tr', class_=lambda x: x and (\"even\" in x or \"odd\" in x))\n",
    "    page_data = []\n",
    "    if action == 'bidding':\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            car_number = cols[0].text\n",
    "            number = car_number[-4:]\n",
    "            price = cols[3].text\n",
    "            page_data.append({\"car_number\": car_number, \"number\": number, \"price\": price, \"page\": page})\n",
    "    else:\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            car_number = cols[0].text\n",
    "            number = car_number[-4:]\n",
    "            price = cols[4].text\n",
    "            page_data.append({\"car_number\": car_number, \"number\": number, \"price\": price, \"page\": page})\n",
    "\n",
    "    return page_data\n",
    "    \n",
    "# 競標\n",
    "def get_bidding_by_station(**params):\n",
    "    \"\"\"\n",
    "    Scrape and analyze bidding data for a specific Taiwan Motor Vehicle Driver Information Service (MVDis) station.\n",
    "    \n",
    "    This function retrieves bidding data from the MVDis website for the specified station using the provided parameters.\n",
    "    It then analyzes the car numbers and prices, calculates the sum of the last four digits of each car number,\n",
    "    and determines if each car number is a lucky number based on a predefined lucky number DataFrame.\n",
    "    The results are saved to an Excel file.\n",
    "    \n",
    "    Args:\n",
    "        **params: Parameters including 'stationCode' for the station number.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the scraped and analyzed bidding data.\n",
    "    \"\"\"\n",
    "    action = 'bidding'\n",
    "    headers = {\n",
    "        'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.93 Safari/537.36\"\n",
    "    }\n",
    "    url = \"https://www.mvdis.gov.tw/m3-emv-plate/bid/queryBiding?d-5481-p={page}&stationCode={stationCode}&onChangeItem=2&method=doChangeStation&sectionCode=4#gsc.tab=0\"\n",
    "    data_types = {'Column1': int, '類別': str, '號碼': str, '總和': str}\n",
    "    lucky_number = pd.read_excel(\"./result/lucky_number.xlsx\", dtype=data_types)\n",
    "    \n",
    "    output_data = []\n",
    "    total_pages = extract_number_of_pages(url, headers, **params)\n",
    "    \n",
    "    for page in range(1, total_pages + 1):\n",
    "        output_data.extend(scrape_page_data(url, headers, page, action, **params))\n",
    "    \n",
    "    output_df = pd.DataFrame(output_data)\n",
    "    output_df = output_df.merge(lucky_number, how='left', left_on='number', right_on='號碼')\n",
    "    output_df = output_df.sort_values(by='car_number')\n",
    "    output_df.to_excel(f\"./result/Bidding_{params['stationCode']}.xlsx\", index=False)\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "# 競標紀錄\n",
    "def get_auction_records_by_station(**params):\n",
    "    \"\"\"\n",
    "    Scrape and analyze auction record data for a specific Taiwan Motor Vehicle Driver Information Service (MVDis) station.\n",
    "    \n",
    "    This function retrieves auction record data from the MVDis website for the specified station using the provided parameters.\n",
    "    It then analyzes the car numbers and prices, calculates the sum of the last four digits of each car number,\n",
    "    and determines if each car number is a lucky number based on a predefined lucky number DataFrame.\n",
    "    The results are saved to an Excel file.\n",
    "    \n",
    "    Args:\n",
    "        **params: Parameters including 'stationCode', 'queryYear', 'queryMonth', 'sectionCode', and 'queryDate'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the scraped and analyzed auction record data.\n",
    "    \"\"\"\n",
    "    action = 'auction_records'\n",
    "    headers = {\n",
    "        'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.93 Safari/537.36\"\n",
    "    }\n",
    "    url = \"https://www.mvdis.gov.tw/m3-emv-plate/bid/queryBid?queryType=2&CSRFToken=6fe10d2a-a0fb-479b-b650-2637d59e6a71&d-5481-p={page}&stationCode={stationCode}&onChangeItem=3&queryYear={queryYear}&queryMonth={queryMonth}&method=doChangeStation&sectionCode={sectionCode}&queryDate={queryDate}&queryBidType=2#gsc.tab=0\"\n",
    "    data_types = {'Column1': int, '類別': str, '號碼': str, '總和': str}\n",
    "    lucky_number = pd.read_excel(\"./result/lucky_number.xlsx\", dtype=data_types)\n",
    "\n",
    "    output_data = []\n",
    "    total_pages = extract_number_of_pages(url, headers, **params)\n",
    "    \n",
    "    for page in range(1, total_pages + 1):\n",
    "        output_data.extend(scrape_page_data(url, headers, page, action, **params))\n",
    "    \n",
    "    output_df = pd.DataFrame(output_data)\n",
    "    output_df = output_df.merge(lucky_number, how='left', left_on='number', right_on='號碼')\n",
    "    output_df = output_df.sort_values(by='car_number')\n",
    "    output_df.to_excel(f\"./result/Auction_Records_{params['stationCode']}.xlsx\", index=False)\n",
    "    \n",
    "    return output_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff127e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "# Bidding Example usage\n",
    "station_name = '宜蘭監理站'\n",
    "station_info = station_dict.get(station_name, {})\n",
    "station_code = station_info.get('stationCode')\n",
    "params = {'stationCode': station_code}\n",
    "result_df = get_bidding_by_station(**params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbd9b423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    car_number number price  page  類別    號碼  總和\n",
      "103   BKZ-1389   1389  4000    11  普通  1389  21\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "target_number = '1389'\n",
    "filtered_df = result_df[result_df['number'] == target_number]\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a5bc723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m\n\u001b[0;32m      6\u001b[0m queryDate\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m\n\u001b[0;32m      7\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mstationCode\u001b[39m\u001b[39m'\u001b[39m: station_info\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mstationCode\u001b[39m\u001b[39m'\u001b[39m), \n\u001b[0;32m      9\u001b[0m     \u001b[39m'\u001b[39m\u001b[39msectionCode\u001b[39m\u001b[39m'\u001b[39m: station_info\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39msectionCode\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mqueryDate\u001b[39m\u001b[39m'\u001b[39m:queryDate,\n\u001b[0;32m     13\u001b[0m     }\n\u001b[1;32m---> 14\u001b[0m result_df \u001b[39m=\u001b[39m get_auction_records_by_station(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n",
      "Cell \u001b[1;32mIn[5], line 156\u001b[0m, in \u001b[0;36mget_auction_records_by_station\u001b[1;34m(**params)\u001b[0m\n\u001b[0;32m    153\u001b[0m total_pages \u001b[39m=\u001b[39m extract_number_of_pages(url, headers, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m    155\u001b[0m \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, total_pages \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m--> 156\u001b[0m     output_data\u001b[39m.\u001b[39mextend(scrape_page_data(url, headers, page, action, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams))\n\u001b[0;32m    158\u001b[0m output_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(output_data)\n\u001b[0;32m    159\u001b[0m output_df \u001b[39m=\u001b[39m output_df\u001b[39m.\u001b[39mmerge(lucky_number, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m, left_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumber\u001b[39m\u001b[39m'\u001b[39m, right_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m號碼\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 70\u001b[0m, in \u001b[0;36mscrape_page_data\u001b[1;34m(url, headers, page, action, **params)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[39mScrape data from a specific page of the Taiwan Motor Vehicle Driver Information Service (MVDis) website.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39m    list: A list of dictionaries containing scraped data for each row on the page.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[39mprint\u001b[39m(page)\n\u001b[1;32m---> 70\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url\u001b[39m.\u001b[39;49mformat(page\u001b[39m=\u001b[39;49mpage, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams), headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[0;32m     71\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(response\u001b[39m.\u001b[39mtext, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     72\u001b[0m rows \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind_all(\u001b[39m'\u001b[39m\u001b[39mtr\u001b[39m\u001b[39m'\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x \u001b[39mand\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39meven\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m x \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39modd\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m x))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[39m=\u001b[39mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[39m=\u001b[39mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[0;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\urllib3\\connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    460\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    463\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\lib\\http\\client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1377\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1378\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1379\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\lib\\http\\client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    321\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    322\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\lib\\http\\client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 281\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    283\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\lib\\ssl.py:1242\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1238\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1239\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1240\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1241\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1242\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1244\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\lib\\ssl.py:1100\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1101\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Auction Records Example usage\n",
    "station_name = '南投監理站'\n",
    "station_info = station_dict.get(station_name, {})\n",
    "queryYear=112\n",
    "queryMonth=8\n",
    "queryDate=16\n",
    "params = {\n",
    "    'stationCode': station_info.get('stationCode'), \n",
    "    'sectionCode': station_info.get('sectionCode'),\n",
    "    'queryYear':queryYear,\n",
    "    'queryMonth':queryMonth,\n",
    "    'queryDate':queryDate,\n",
    "    }\n",
    "result_df = get_auction_records_by_station(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e242bbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "target_number = '1358'\n",
    "filtered_df = result_df[result_df['number'] == target_number]\n",
    "print(filtered_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
